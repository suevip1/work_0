DELETE FROM `environment_param_template`;
INSERT INTO `environment_param_template` (`task_type`, `task_name`, `task_version`, `app_type`, `params`, `gmt_create`, `gmt_modified`, `is_deleted`) VALUES
(0, 'SPARK_SQL', '2.1', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2021-11-18 10:36:13', '2021-11-18 10:36:13', 0),
(0, 'SPARK_SQL', '2.4', -1, '## Driver程序使用的CPU核数,默认为1\n# spark.driver.cores=1\n\n## Driver程序使用内存大小,默认1g\n# spark.driver.memory=1g\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# spark.driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\n# spark.executor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\n# spark.executor.cores=1\n\n## 每个executor内存大小,默认1g\n# spark.executor.memory=1g\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead=\n\n## 设置spark sql shuffle分区数，默认200\n# spark.sql.shuffle.partitions=200\n\n## 开启spark推测行为，默认false\n# spark.speculation=false', '2021-11-18 10:36:13', '2021-11-18 10:36:13', 0),
(1, 'SPARK', '2.1', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2021-11-18 10:36:13', '2021-11-18 10:36:13', 0),
(1, 'SPARK', '2.4', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2021-11-18 10:36:13', '2021-11-18 10:36:13', 0),
(2, 'SYNC', '1.8', -1, '## 任务运行方式：\n## per_job:单独为任务创建flink yarn session，适用于低频率，大数据量同步\n## session：多个任务共用一个flink yarn session，适用于高频率、小数据量同步，默认session\n## flinkTaskRunMode=per_job\n## per_job模式下jobManager配置的内存大小，默认1024（单位M)\n## jobmanager.memory.mb=1024\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n## taskmanager.memory.mb=1024\n## per_job模式下启动的taskManager数量\n## container=1\n## per_job模式下每个taskManager 对应 slot的数量\n## slots=1\n## checkpoint保存时间间隔\n## flink.checkpoint.interval=300000\n## 任务优先级, 范围:1-1000\n## ', '2021-11-18 10:37:24', '2021-11-18 10:37:24', 0),
(2, 'SYNC', '1.10', -1, '## 任务运行方式：\n## per_job:单独为任务创建flink yarn session，适用于低频率，大数据量同步\n## session：多个任务共用一个flink yarn session，适用于高频率、小数据量同步，默认session\n## flinkTaskRunMode=per_job\n## per_job模式下jobManager配置的内存大小，默认1024（单位M)\n## jobmanager.memory.mb=1024\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n## taskmanager.memory.mb=1024\n## per_job模式下每个taskManager 对应 slot的数量\n## slots=1\n\n## checkpoint保存时间间隔\n## flink.checkpoint.interval=300000\n## 任务优先级, 范围:1-1000\n## \npipeline.operator-chaining = false', '2021-11-18 10:37:24', '2021-11-18 10:37:24', 0),
(2, 'SYNC', '1.12', -1, '## 任务运行方式：\n## per_job:单独为任务创建flink yarn session，适用于低频率，大数据量同步\n## session：多个任务共用一个flink yarn session，适用于高频率、小数据量同步，默认session\n## flinkTaskRunMode=per_job\n## per_job模式下jobManager配置的内存大小，默认1024（单位M)\n## jobmanager.memory.mb=1024\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n## taskmanager.memory.mb=1024\n## per_job模式下每个taskManager 对应 slot的数量\n## slots=1\n\n## checkpoint保存时间间隔\n## flink.checkpoint.interval=300000\n## 任务优先级, 范围:1-1000\n## \npipeline.operator-chaining = false', '2021-11-18 10:37:24', '2021-11-18 10:37:24', 0),
(3, 'SPARK_PYTHON', '2.1', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2021-11-18 10:37:54', '2021-11-18 10:37:54', 0),
(3, 'SPARK_PYTHON', '2.4', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2021-11-18 10:37:54', '2021-11-18 10:37:54', 0),
(6, 'PYTHON', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=512m\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 是否独占机器节点\nexclusive=false\n\n## worker数量\nworker.num=1\n\n## 指定运行节点, 示例：nodes=hostname1,hostname2\n## nodes=\n\n## 指定机架, 示例：racks=racks,racks\n## racks=\n\n##任务优先级, 值越小，优先级越高，范围:1-1000\n ', '2021-11-18 10:38:51', '2021-11-18 10:38:51', 0),
(7, 'SHELL', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=512m\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 是否独占机器节点\nexclusive=false\n\n## worker数量\nworker.num=1\n\n## 指定运行节点, 示例：nodes=hostname1,hostname2\n## nodes=\n\n## 指定机架, 示例：racks=racks,racks\n## racks=\n\n##任务优先级, 值越小，优先级越高，范围:1-1000\n ', '2021-11-18 10:39:11', '2021-11-18 10:39:11', 0),
(13, 'NOTEBOOK', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=512m\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 是否独占机器节点\nexclusive=false\n\n## worker数量\nworker.num=1\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n', '2021-11-18 10:39:59', '2021-11-18 10:39:59', 0),
(17, 'HIVE_SQL', NULL, -1, '## 指定mapreduce在yarn上的任务名称，默认为任务名称，可以重复\n#hiveconf:mapreduce.job.name=\n\n## 指定mapreduce运行的队列，默认走控制台配置的queue\n# hiveconf:mapreduce.job.queuename=default_queue_name\n\n## hivevar配置,用户自定义变量\n#hivevar:ageParams=30', '2021-11-18 10:40:27', '2021-11-18 10:40:27', 0),
(22, 'TENSORFLOW_1_X', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=1024m\n\n## worker的数量\nworker.num=1\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n', '2021-11-18 10:40:47', '2021-11-18 10:40:47', 0),
(23, 'KERAS', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=1024m\n\n## worker的数量\nworker.num=1\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n', '2021-11-18 10:41:05', '2021-11-18 10:41:05', 0),
(25, 'PYTORCH', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=1024m\n\n## worker的数量\nworker.num=1\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n', '2021-11-18 10:41:23', '2021-11-18 10:41:23', 0),
(31, 'FLINK_SQL', '1.8', -1, '## sql任务并发度设置\nsql.env.parallelism=1\n\n## 时间窗口类型（ProcessingTime或者EventTime）\ntime.characteristic=ProcessingTime\n\n## 窗口提前触发时间，单位为秒(填写正整数即可)\n# early.trigger=1\n\n## ttl状态控制\n## 最小过期时间,大于0的整数,如1d、1h(dD:天,hH:小时,mM:分钟,ss:秒)\n# sql.ttl.min=1h\n## 最大过期时间,大于0的整数,如2d、2h(dD:天,hH:小时,mM:分钟,ss:秒),需同时设置最小时间,且比最小时间大5分钟\n# sql.ttl.max=2h\n\n## 生成checkpoint时间间隔（以毫秒为单位），默认:5分钟,注释掉该选项会关闭checkpoint生成\nflink.checkpoint.interval=300000\n\n## 设置checkpoint生成超时（以毫秒为单位），默认:10分钟\nsql.checkpoint.timeout=600000\n\n## 任务出现故障的时候一致性处理,可选参数EXACTLY_ONCE,AT_LEAST_ONCE；默认为EXACTLY_ONCE\n# sql.checkpoint.mode=EXACTLY_ONCE\n\n## 最大并发生成 checkpoint 数量，默认：1 次\n# sql.max.concurrent.checkpoints=1\n\n## checkpoint 外存的清理动作\n## true（任务结束之后删除checkpoint外部存储信息）\n## false（任务结束之后保留checkpoint外部存储信息）\nsql.checkpoint.cleanup.mode=false\n\n## jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n\n## taskManager 对应 slot的数量\nslots=1\n\n## logLevel: error,debug,info(默认),warn\nlogLevel=info\n\n## Watermark发送周期，单位毫秒\n# autoWatermarkInterval=200\n\n## 设置输出缓冲区的最大刷新时间频率（毫秒）\n# sql.buffer.timeout.millis=100\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## kafka kerberos相关参数\n## security.kerberos.login.use-ticket-cache=true\n## security.kerberos.login.contexts=Client,KafkaClient\n## security.kerberos.login.keytab=/opt/keytab/kafka.keytab\n## security.kerberos.login.principal=kafka@HADOOP.COM\n## zookeeper.sasl.service-name=zookeeper\n## zookeeper.sasl.login-context-name=Client\n\n\n## 异步访问维表是否开启连接池共享,开启则 1.一个tm上多个task共享该池, 2.一个tm上多个url相同的维表单/多个task共享该池 (默认false)\n# async.side.clientShare=false\n## 连接池中连接的个数,上面参数为true才生效(默认5)\n# async.side.poolSize=5', '2021-11-18 10:42:19', '2021-11-18 10:42:19', 0),
(31, 'FLINK_SQL', '1.10', -1, '## sql任务并发度设置\nsql.env.parallelism=1\n\n## 时间窗口类型（ProcessingTime或者EventTime）\ntime.characteristic=ProcessingTime\n\n## 窗口提前触发时间，单位为秒(填写正整数即可)\n# early.trigger=1\n\n## ttl状态控制\n## 最小过期时间,大于0的整数,如1d、1h(dD:天,hH:小时,mM:分钟,ss:秒)\n# sql.ttl.min=1h\n## 最大过期时间,大于0的整数,如2d、2h(dD:天,hH:小时,mM:分钟,ss:秒),需同时设置最小时间,且比最小时间大5分钟\n# sql.ttl.max=2h\n\n## 生成checkpoint时间间隔（以毫秒为单位），默认:5分钟,注释掉该选项会关闭checkpoint生成\nflink.checkpoint.interval=300000\n\n## 设置checkpoint生成超时（以毫秒为单位），默认:10分钟\nsql.checkpoint.timeout=600000\n\n## 任务出现故障的时候一致性处理,可选参数EXACTLY_ONCE,AT_LEAST_ONCE；默认为EXACTLY_ONCE\n# sql.checkpoint.mode=EXACTLY_ONCE\n\n## 最大并发生成 checkpoint 数量，默认：1 次\n# sql.max.concurrent.checkpoints=1\n\n## checkpoint 外存的清理动作\n## true（任务结束之后删除checkpoint外部存储信息）\n## false（任务结束之后保留checkpoint外部存储信息）\nsql.checkpoint.cleanup.mode=false\n\n## jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n\n## taskManager 对应 slot的数量\nslots=1\n\n## logLevel: error,debug,info(默认),warn\nlogLevel=info\n\n## Watermark发送周期，单位毫秒\n# autoWatermarkInterval=200\n\n## 设置输出缓冲区的最大刷新时间频率（毫秒）\n# sql.buffer.timeout.millis=100\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## kafka kerberos相关参数\n## security.kerberos.login.use-ticket-cache=true\n## security.kerberos.login.contexts=Client,KafkaClient\n## security.kerberos.login.keytab=/opt/keytab/kafka.keytab\n## security.kerberos.login.principal=kafka@HADOOP.COM\n## zookeeper.sasl.service-name=zookeeper\n## zookeeper.sasl.login-context-name=Client\n\n\n## 异步访问维表是否开启连接池共享,开启则 1.一个tm上多个task共享该池, 2.一个tm上多个url相同的维表单/多个task共享该池 (默认false)\n# async.side.clientShare=false\n## 连接池中连接的个数,上面参数为true才生效(默认5)\n# async.side.poolSize=5', '2021-11-18 10:42:19', '2021-11-18 10:42:19', 0),
(31, 'FLINK_SQL', '1.12', -1, '## 资源相关\nparallelism.default=1\ntaskmanager.numberOfTaskSlots=1\njobmanager.memory.process.size=1g\ntaskmanager.memory.process.size=2g\n\n## 时间相关\n## 设置Flink时间选项，有ProcessingTime,EventTime,IngestionTime可选\n## 非脚本模式会根据Kafka自动设置。脚本模式默认为ProcessingTime\n# pipeline.time-characteristic=EventTime\n\n## Checkpoint相关\n## 生成checkpoint时间间隔（以毫秒为单位），默认:5分钟,注释掉该选项会关闭checkpoint生成\nexecution.checkpointing.interval=5min\n## 状态恢复语义,可选参数EXACTLY_ONCE,AT_LEAST_ONCE；默认为EXACTLY_ONCE\n# execution.checkpointing.mode=EXACTLY_ONCE\n\n# Flink SQL独有，状态过期时间\ntable.exec.state.ttl=1d\n\nlog.level=INFO\n\n## 使用Iceberg和Hive维表开启\n# table.dynamic-table-options.enabled=true\n\n## Kerberos相关\n# security.kerberos.login.contexts=Client,KafkaClient\n\n\n## 高阶参数\n## 窗口提前触发时间\n# table.exec.emit.early-fire.enabled=true\n# table.exec.emit.early-fire.delay=1s\n\n## 当一个源在超时时间内没有收到任何元素时，它将被标记为临时空闲\n# table.exec.source.idle-timeout=10ms\n\n## 是否开启minibatch\n## 可以减少状态开销。这可能会增加一些延迟，因为它会缓冲一些记录而不是立即处理它们。这是吞吐量和延迟之间的权衡\n# table.exec.mini-batch.enabled=true\n## 状态缓存时间\n# table.exec.mini-batch.allow-latency=5s\n## 状态最大缓存条数\n# table.exec.mini-batch.size=5000\n\n## 是否开启Local-Global 聚合。前提需要开启minibatch\n## 聚合是为解决数据倾斜问题提出的，类似于 MapReduce 中的 Combine + Reduce 模式\n# table.optimizer.agg-phase-strategy=TWO_PHASE\n\n## 是否开启拆分 distinct 聚合\n## Local-Global 可以解决数据倾斜，但是在处理 distinct 聚合时，其性能并不令人满意。\n## 如：SELECT day, COUNT(DISTINCT user_id) FROM T GROUP BY day 如果 distinct key （即 user_id）的值分布稀疏，建议开启\n# table.optimizer.distinct-agg.split.enabled=true\n\n## Flink算子chaining开关。默认为true。排查性能问题时会暂时设置成false，但降低性能。\n# pipeline.operator-chaining=true\nexecution.checkpointing.externalized-checkpoint-retention=RETAIN_ON_CANCELLATION', '2021-11-18 10:42:19', '2021-11-18 10:42:19', 0),
(37, 'DATA_COLLECTION', '1.8', -1, '## per_job模式下jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n## per_job模式下启动的taskManager数量\n# container=1\n\n## per_job模式下每个taskManager 对应 slot的数量\nslots=1\n\n## 任务优先级, 范围:1-1000\n\n\n## checkpoint保存时间间隔\nflink.checkpoint.interval=3600000\n\n## kafka kerberos相关参数\n## security.kerberos.login.use-ticket-cache=true\n## security.kerberos.login.contexts=Client,KafkaClient\n## security.kerberos.login.keytab=/opt/keytab/kafka.keytab\n## security.kerberos.login.principal=kafka@HADOOP.COM\n## zookeeper.sasl.service-name=zookeeper\n## zookeeper.sasl.login-context-name=Client', '2021-11-18 10:43:42', '2021-11-18 10:43:42', 0),
(37, 'DATA_COLLECTION', '1.10', -1, '## per_job模式下jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n## per_job模式下启动的taskManager数量\n# container=1\n\n## per_job模式下每个taskManager 对应 slot的数量\nslots=1\n\n## 任务优先级, 范围:1-1000\n\n\n## checkpoint保存时间间隔\nflink.checkpoint.interval=3600000\n\n## kafka kerberos相关参数\n## security.kerberos.login.use-ticket-cache=true\n## security.kerberos.login.contexts=Client,KafkaClient\n## security.kerberos.login.keytab=/opt/keytab/kafka.keytab\n## security.kerberos.login.principal=kafka@HADOOP.COM\n## zookeeper.sasl.service-name=zookeeper\n## zookeeper.sasl.login-context-name=Client', '2021-11-18 10:43:42', '2021-11-18 10:43:42', 0),
(37, 'DATA_COLLECTION', '1.12', -1, '## 资源相关\nparallelism.default=1\ntaskmanager.numberOfTaskSlots=1\njobmanager.memory.process.size=1g\ntaskmanager.memory.process.size=2g\n\n## 时间相关\n## 设置Flink时间选项，有ProcessingTime,EventTime,IngestionTime可选\n## 默认为ProcessingTime\n# pipeline.time-characteristic=EventTime\n\n## Checkpoint相关\n## 生成checkpoint时间间隔（以毫秒为单位），默认:5分钟,注释掉该选项会关闭checkpoint生成\nexecution.checkpointing.interval=5min\n## 状态恢复语义,可选参数EXACTLY_ONCE,AT_LEAST_ONCE；默认为EXACTLY_ONCE\n# execution.checkpointing.mode=EXACTLY_ONCE\n\n## Kerberos相关参数\n# security.kerberos.login.contexts=Client,KafkaClient\nexecution.checkpointing.externalized-checkpoint-retention=RETAIN_ON_CANCELLATION', '2021-11-18 10:43:42', '2021-11-18 10:43:42', 0),
(38, 'TONY', NULL, -1, '## 实例个数\ntony.am.instances = 1\n\n# 内存大小，字符串格式\ntony.am.memory = 2g\n\n# 核数\ntony.am.vcores = 1\n\n# gpu个数\ntony.am.gpus = 0\n\n# 实例个数\ntony.ps.instances = 0\n\n# 内存大小，字符串格式\ntony.ps.memory = 2g\n\n# 核数\ntony.ps.vcores = 1\n\n# gpu个数\ntony.ps.gpus = 0\n\n# worker实例个数\ntony.worker.instances = 0\n\n# 内存大小，字符串格式\ntony.worker.memory = 2g\n\n# 核数\ntony.worker.vcores = 1\n\n# gpu个数\ntony.worker.gpus = 0\n', '2021-11-18 11:01:30', '2021-11-18 11:01:30', 0),
(39, 'FLINK', '1.8', -1, '## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n\n## taskManager数量\n# container=1\n\n## taskManager 对应 slot的数量\nslots=1\n', '2021-11-18 14:29:02', '2021-11-18 14:29:02', 0),
(39, 'FLINK', '1.10', -1, '## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n\n## taskManager数量\n# container=1\n\n## taskManager 对应 slot的数量\nslots=1\n', '2021-11-18 14:29:02', '2021-11-18 14:29:02', 0),
(39, 'FLINK', '1.12', -1, '## 资源相关\n## per_job:单独为任务创建flink yarn\nflinkTaskRunMode=per_job\n## jar包任务没设置并行度时的默认并行度\nparallelism.default=1\n#t# askmanager的slot数\ntaskmanager.numberOfTaskSlots=1\n## jobmanager进程内存大小\njobmanager.memory.process.size=1g\n## taskmanager进程内存大小\ntaskmanager.memory.process.size=2g', '2021-11-18 14:29:02', '2021-11-18 14:29:02', 0),
(36, 'TRINO', NULL, -1, '', '2022-05-17 16:13:50', '2022-05-17 16:13:50', 0),
(0, 'SPARK_SQL', '3.2', -1, '## Driver程序使用的CPU核数,默认为1\n# spark.driver.cores=1\n\n## Driver程序使用内存大小,默认1g\n# spark.driver.memory=1g\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# spark.driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\n# spark.executor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\n# spark.executor.cores=1\n\n## 每个executor内存大小,默认1g\n# spark.executor.memory=1g\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead=\n\n## 设置spark sql shuffle分区数，默认200\n# spark.sql.shuffle.partitions=200\n\n## 开启spark推测行为，默认false\n# spark.speculation=false', '2023-08-19 00:55:52', '2023-08-19 00:55:52', 0),
(3, 'SPARK_PYTHON', '3.2', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2023-08-19 00:55:52', '2023-08-19 00:55:52', 0),
(1, 'SPARK', '3.2', -1, '## Driver程序使用的CPU核数,默认为1\n# driver.cores=1\n\n## Driver程序使用内存大小,默认512m\n# driver.memory=512m\n\n## 对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n## 若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n# driver.maxResultSize=1g\n\n## 启动的executor的数量，默认为1\nexecutor.instances=1\n\n## 每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n## 每个executor内存大小,默认512m\nexecutor.memory=512m\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n## spark 日志级别可选ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n# logLevel = INFO\n\n## spark中所有网络交互的最大超时时间\n# spark.network.timeout=120s\n\n## executor的OffHeap内存，和spark.executor.memory配置使用\n# spark.yarn.executor.memoryOverhead', '2023-08-19 00:55:52', '2023-08-19 00:55:52', 0),
(5, 'DEEP_LEARNING', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=512m\n\n## worker的数量\nworker.num=1\n\n## 每个worker所占的cpu核的数量\nworker.cores=1\n\n## 任务优先级, 值越小，优先级越高，范围:1-1000\n', '2023-08-19 00:57:25', '2023-08-19 00:57:25', 0),
(9, 'HADOOP_MR', NULL, -1, '', '2023-08-19 00:57:26', '2023-08-19 00:57:26', 0),
(12, 'CARBON_SQL', NULL, -1, '##Driver程序使用的CPU核数,默认为1\n##driver.cores=1\n\n##Driver程序使用内存大小,默认512m\n##driver.memory=512m\n\n##对Spark每个action结果集大小的限制，最少是1M，若设为0则不限制大小。\n##若Job结果超过限制则会异常退出，若结果集限制过大也可能造成OOM问题，默认1g\n##driver.maxResultSize=1g\n\n##SparkContext 启动时是否记录有效 SparkConf信息,默认false\n##logConf=false\n\n\n##启动的executor的数量，默认为1\nexecutor.instances=1\n\n#每个executor使用的CPU核数，默认为1\nexecutor.cores=1\n\n##每个executor内存大小,默认512m\n##executor.memory=512m\nisCarbondata=true\n\n##任务优先级, 值越小，优先级越高，范围:1-1000\n', '2023-08-19 00:57:27', '2023-08-19 00:57:27', 0),
(15, 'LIBRA_SQL', NULL, -1, '', '2023-08-19 00:57:27', '2023-08-19 00:57:27', 0),
(18, 'IMPALA_SQL', NULL, -1, '', '2023-08-19 00:57:28', '2023-08-19 00:57:28', 0),
(19, 'TIDB_SQL', NULL, -1, '', '2023-08-19 00:57:29', '2023-08-19 00:57:29', 0),
(20, 'ORACLE_SQL', NULL, -1, '', '2023-08-19 00:57:29', '2023-08-19 00:57:29', 0),
(21, 'GREENPLUM_SQL', NULL, -1, '', '2023-08-19 00:57:30', '2023-08-19 00:57:30', 0),
(28, 'INCEPTOR_SQL', NULL, -1, '', '2023-08-19 00:57:31', '2023-08-19 00:57:31', 0),
(30, 'ANALYTICDB_FOR_PG', NULL, -1, '', '2023-08-19 00:57:31', '2023-08-19 00:57:31', 0),
(32, 'MYSQL', NULL, -1, '', '2023-08-19 00:57:32', '2023-08-19 00:57:32', 0),
(33, 'SQL_SERVER', NULL, -1, '', '2023-08-19 00:57:33', '2023-08-19 00:57:33', 0),
(34, 'DB2', NULL, -1, '', '2023-08-19 00:57:33', '2023-08-19 00:57:33', 0),
(35, 'OCEANBASE', NULL, -1, '', '2023-08-19 00:57:34', '2023-08-19 00:57:34', 0),
(99, 'FILE_COPY', NULL, -1, '## 每个worker所占内存，比如512m\nworker.memory=512m\n\n        ## 每个worker所占的cpu核的数量\nworker.cores=1\n\n        ## 任务优先级, 值越小，优先级越高，范围:1-1000\n\n\n        ## 根据nodes的值 可将任务指定在某些节点运行\n\n        ## nodes=node001\n', '2023-08-19 00:57:44', '2023-08-19 00:57:44', 0),
(44, 'STARROCKS', NULL, -1, '', '2023-08-19 00:58:04', '2023-08-19 00:58:04', 0),
(45, 'HASHDATA', NULL, -1, '', '2023-08-19 00:58:05', '2023-08-19 00:58:05', 0),
(39, 'FLINK', '1.16', -1, '## 资源相关\n## per_job:单独为任务创建flink yarn\nflinkTaskRunMode=per_job\n## jar包任务没设置并行度时的默认并行度\nparallelism.default=1\n#t# askmanager的slot数\ntaskmanager.numberOfTaskSlots=1\n## jobmanager进程内存大小\njobmanager.memory.process.size=1g\n## taskmanager进程内存大小\ntaskmanager.memory.process.size=2g', '2023-08-19 00:59:49', '2023-08-19 00:59:49', 0),
(31, 'FLINK_SQL', '1.16', -1, '## 资源相关\nparallelism.default=1\ntaskmanager.numberOfTaskSlots=1\njobmanager.memory.process.size=1g\ntaskmanager.memory.process.size=2g\n\n## 时间相关\n## 设置Flink时间选项，有ProcessingTime,EventTime,IngestionTime可选\n## 非脚本模式会根据Kafka自动设置。脚本模式默认为ProcessingTime\n# pipeline.time-characteristic=EventTime\n\n## Checkpoint相关\n## 生成checkpoint时间间隔（以毫秒为单位），默认:5分钟,注释掉该选项会关闭checkpoint生成\nexecution.checkpointing.interval=5min\n## 状态恢复语义,可选参数EXACTLY_ONCE,AT_LEAST_ONCE；默认为EXACTLY_ONCE\n# execution.checkpointing.mode=EXACTLY_ONCE\n\n# Flink SQL独有，状态过期时间\ntable.exec.state.ttl=1d\n\nlog.level=INFO\n\n## 使用Iceberg和Hive维表开启\n# table.dynamic-table-options.enabled=true\n\n## Kerberos相关\n# security.kerberos.login.contexts=Client,KafkaClient\n\n\n## 高阶参数\n## 窗口提前触发时间\n# table.exec.emit.early-fire.enabled=true\n# table.exec.emit.early-fire.delay=1s\n\n## 当一个源在超时时间内没有收到任何元素时，它将被标记为临时空闲\n# table.exec.source.idle-timeout=10ms\n\n## 是否开启minibatch\n## 可以减少状态开销。这可能会增加一些延迟，因为它会缓冲一些记录而不是立即处理它们。这是吞吐量和延迟之间的权衡\n# table.exec.mini-batch.enabled=true\n## 状态缓存时间\n# table.exec.mini-batch.allow-latency=5s\n## 状态最大缓存条数\n# table.exec.mini-batch.size=5000\n\n## 是否开启Local-Global 聚合。前提需要开启minibatch\n## 聚合是为解决数据倾斜问题提出的，类似于 MapReduce 中的 Combine + Reduce 模式\n# table.optimizer.agg-phase-strategy=TWO_PHASE\n\n## 是否开启拆分 distinct 聚合\n## Local-Global 可以解决数据倾斜，但是在处理 distinct 聚合时，其性能并不令人满意。\n## 如：SELECT day, COUNT(DISTINCT user_id) FROM T GROUP BY day 如果 distinct key （即 user_id）的值分布稀疏，建议开启\n# table.optimizer.distinct-agg.split.enabled=true\n\n## Flink算子chaining开关。默认为true。排查性能问题时会暂时设置成false，但降低性能。\n# pipeline.operator-chaining=true\nexecution.checkpointing.externalized-checkpoint-retention=RETAIN_ON_CANCELLATION', '2023-08-19 00:59:50', '2023-08-19 00:59:50', 0),
(2, 'SYNC', '1.16', -1, '## 任务运行方式：\n## per_job:单独为任务创建flink yarn session，适用于低频率，大数据量同步\n## session：多个任务共用一个flink yarn session，适用于高频率、小数据量同步，默认session\n## flinkTaskRunMode=per_job\n## per_job模式下jobManager配置的内存大小，默认1024（单位M)\n## jobmanager.memory.mb=1024\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n## taskmanager.memory.mb=1024\n## per_job模式下每个taskManager 对应 slot的数量\n## slots=1\n\n## checkpoint保存时间间隔\n## flink.checkpoint.interval=300000\n## 任务优先级, 范围:1-1000\n## \npipeline.operator-chaining = false', '2023-08-19 00:59:50', '2023-08-19 00:59:50', 0),
(37, 'DATA_COLLECTION', '1.16', -1, '## per_job模式下jobManager配置的内存大小，默认1024（单位M）\n# jobmanager.memory.mb=1024\n\n## per_job模式下taskManager配置的内存大小，默认1024（单位M）\n# taskmanager.memory.mb=1024\n## per_job模式下启动的taskManager数量\n# container=1\n\n## per_job模式下每个taskManager 对应 slot的数量\nslots=1\n\n## 任务优先级, 范围:1-1000\n\n\n## checkpoint保存时间间隔\nflink.checkpoint.interval=3600000\n\n## kafka kerberos相关参数\n## security.kerberos.login.use-ticket-cache=true\n## security.kerberos.login.contexts=Client,KafkaClient\n## security.kerberos.login.keytab=/opt/keytab/kafka.keytab\n## security.kerberos.login.principal=kafka@HADOOP.COM\n## zookeeper.sasl.service-name=zookeeper\n## zookeeper.sasl.login-context-name=Client', '2023-08-19 00:59:51', '2023-08-19 00:59:51', 0);